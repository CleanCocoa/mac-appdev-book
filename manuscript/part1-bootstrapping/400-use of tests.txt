## Use of Automated Tests

Considering the circumstances and the high uncertainty of my situation, tests have more benefits than verifying the behavior of components:

* Regression Tests: they ensure I don't break the functionality.
* Discovery Tests: they become client code to find out how well the parts fit together.
* Discovery Tests II: they help me learn the new language and its API. I can formalize expectations (based on my Objective-C experiences) and try to replicate behavior in Swift.

Discovery Tests are tests which aren't necessarily meant to stay. They take the place of `NSLog`ging values in production code. Instead of fiddling with the app itself, running it, and looking at values at breakpoints, you write expectations about implementation details and fiddle with the code until the tests pass. Afterwards, you get rid of the tests if you think they're not covering what should be tested.

For example, in this project I try not to unit test every little detail. I want to add more functional tests which involve a whole graph of actual objects interacting with each other. So I'll have to consider removing tests which don't add a lot of benefit for the overhead of keeping them in sync with production code.

### Test-Driven Development on the Unit Level VS Functional Tests

In the past I would've tried hard to develop my code driven by tests _on the unit level_.

This poses an interesting challenge to the code's design, and it maybe affects the flexibility of the implementation.

Let's say I have to add an algorithm `sum(input: [Int]) -> Int` which involves iterating over an array to sum up its elements. That's a straight-forward task none of us would need to think twice about.

When doing hardcore Test-Driven Development, though, I'd to test the return value this algorithm according to the [Transformation Priority Premise][martin-tpp] like this:

1. Pass test for 1 element in: return a fixed value
2. Pass test for 1 different element in: resort to returning the only value in the array
3. For 2 elements in: if the element count is 2, return the sum of both elements
4. 10 elements in: loop over the array and return a sum of its elements

Only in the last case I actually _have_ to resort to using a loop to get the easiest implementation to satisfy the expectations. I've truly developed the code guided by tests, avoiding to jump too far ahead at every point in time. 

The _Transformation Priority Premise_ totally makes sense to me: avoid premature optimization. Think simple. If you haven't read it, yet, I suggest you [do so right now.][martin-tpp]

But what do you do with the earlier tests once you're at stage 4? Are all of them needed to verify that the algorithm works as expected?

Keeping only the 4th test doesn't suffice: you could hard code the sum of the 10 elements from your test as the return value. In other words, you fall back to the "return constant" step. What if you pass in a different array? Wrong result! You need more than one test at any given point in time to verify the algorithm keeps computing the values like it did before.

Transferring this insight to not so trivial code poses the following challenge: find out which tests were necessary during _discovery_ and ditch these. Keep the rest. Too many tests can actually hurt your application because they make it harder to do changes. Testing only _The Right Thing_ is hard. Maybe there's no guiding principle at all. At least I haven't found any.

[martin-tpp]: http://blog.8thlight.com/uncle-bob/2013/05/27/TheTransformationPriorityPremise.html


### Tests Should Prioritize Refactoring

<!--ct: ยง201408131755 Tests sollten Refaktorisierungen priorisieren-->

So I am puzzled. I thought that having more tests is always better, because you cover more and more edge cases with each test. But then again, too rigid testing makes code too hard to change.

One necessary condition of successful [refactoring][] is that you have to be able to change the implementation without changing the behavior, thus breaking collaborators's expectations. On one hand, too explicit a test can be broken by refactoring code. So [tests can actually make refactoring harder.][objc2] On the other hand, refactoring code without tests is always a gamble: you can break behavior without noticing.

> Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior.  
> --- [Martin Fowler](http://www.refactoring.com/)

It's hard for me to find a balance. But since I [publish the code of this project][bookcode], maybe with the help of other developers all of us can learn something about weighing test coverage. I'd appreciate a good discussion on the topic.

In short, my guideline is the following:

* Use tests to find out how components work together,
* verify expected behavior through tests, making sure to cover edge cases,
* remove discovery tests, and
* remove tests which make too many assumptions about the internals in favor for black-box testing to make refactoring easier.

With the years, I tend to do more and more functional testing or integration testing and try not to be too anal about unit tests, or else I end up with at least two places for any change I want to make.

[objc2]: http://www.objc.io/issue-15/bad-testing-practices.html
[refactoring]: http://c2.com/cgi/wiki?WhatIsRefactoring
[bookcode]: https://github.com/DivineDominion/mac-appdev-code
